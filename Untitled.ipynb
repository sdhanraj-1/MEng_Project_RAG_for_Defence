{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284e8e76-1629-4936-9e5e-2fda367a2c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# Document loading, retrieval methods and text splitting\n",
    "%pip install -qU langchain langchain_community\n",
    "\n",
    "# Local vector store via Chroma\n",
    "%pip install -qU langchain_chroma\n",
    "\n",
    "# Local inference and embeddings via Ollama\n",
    "%pip install -qU langchain_ollama\n",
    "\n",
    "# Web Loader\n",
    "% pip install -qU beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b69a4-c450-4ba0-8c46-8801c1b857a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://python.langchain.com/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html#langchain_ollama.llms.OllamaLLM.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57292e5-f47c-4bd7-9524-4bc3404400ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f90d1b-6644-4d04-bc80-63928691670d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b673c70a-35cf-4e63-a011-f9b82b880d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf31aea-6c44-4230-819a-eaf9c987aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c510951-fafc-422f-a97d-140f1b49e9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8266b58e-e302-44e8-9eca-2a7b963b8ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='6afde98b-1718-490b-a74d-e68a59809166', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12f487f4-b5cf-4380-8fdc-cf9990a8d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"llama3.2:1b\",\n",
    "    num_gpu = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf909c8a-1554-4b04-b327-4a2516da4720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Scene is Set**\n",
      "\n",
      "The stage is set in a crowded comedy club, the lights are bright, and the crowd is electric. The audience cheers as two of the world's most renowned comedians, Stephen Colbert and John Oliver, take to the mic. The commentators, a popular TV host and comedian, introduce the battle.\n",
      "\n",
      "Commentator 1: \"Welcome back, folks! Tonight, we've got a real barnburner for you. The master of satire, Stephen Colbert, takes on the king of mocking, John Oliver!\"\n",
      "\n",
      "Commentator 2: \"That's right, Bob. These two comedians have been trading barbs for years, and it's about to get ugly.\"\n",
      "\n",
      "Stephen Colbert steps up to the mic first.\n",
      "\n",
      "**Stephen Colbert**\n",
      "\n",
      "Yo, John, I heard you've been talking smack\n",
      "About my show, saying it's whack\n",
      "But let me tell you, I'm the king of this throne\n",
      "My satire is sharp, it never feels overthrown\n",
      "\n",
      "I tackle the tough topics with flair and finesse\n",
      "You just rant and rave like a liberal mess\n",
      "My guests are clever, my jokes are on point\n",
      "You're just shouting into the void, without a thought\n",
      "\n",
      "John Oliver may have his little show\n",
      "But I've got the real deal, don't you know?\n",
      "I'm the one who brings the laughs with style and panache\n",
      "You're just a one-trick pony, with a bunch of empty chatter\n",
      "\n",
      "**John Oliver**\n",
      "\n",
      "Stephen, Stephen, Stephen, always so full of yourself\n",
      "Think you're king, but your show is old news for wealth\n",
      "My show may not be flashy, but it's bold and true\n",
      "I tackle the real issues, while you just make me swoon to the cluelessness too\n",
      "\n",
      "You may have the ratings, but I've got the facts on my side\n",
      "You rely on your guests to tell the story with pride\n",
      "But let's be real, Stephen, they're not exactly saints\n",
      "They're either out of touch or just plain caught\n",
      "\n",
      "My show is where it's at, no need for your snarky little face\n",
      "I'm the one who makes you look silly in a good way, that's my ace\n",
      "So bring it on, Stephen, I dare you to try and take me down\n",
      "But your insults won't work, they're just spinning round and round\n",
      "\n",
      "**The Crowd Goes Wild**\n",
      "\n",
      "Commentator 1: \"It's getting intense! The crowd is loving this!\"\n",
      "\n",
      "Commentator 2: \"Yes, John Oliver is giving him a run for his money. This could be epic.\"\n",
      "\n",
      "Stephen Colbert responds.\n",
      "\n",
      "**Stephen Colbert**\n",
      "\n",
      "Oh, John, you think you're clever, don't you?\n",
      "But your show may have some facts on it, but they're not all true\n",
      "You rely on your guests to tell the story with flair\n",
      "While I just stick to the facts, and leave out whatever's rare\n",
      "\n",
      "My show is scripted, John, that's a fact\n",
      "You're just winging it, trying to play the part of the fact\n",
      "But let's face it, Stephen, you're not as slick as you think\n",
      "Your jokes are tired, your satire's whacked\n",
      "\n",
      "**John Oliver**\n",
      "\n",
      "Stephen, Stephen, Stephen, you're just mad because you lost\n",
      "Your show is dying, and I'm on top, no need to boast\n",
      "I've got the ratings, I've got the fame\n",
      "While you're stuck in the shadows, with a fading name\n",
      "\n",
      "My show may not be perfect, but it's authentic and true\n",
      "I talk about the issues that matter, while you just pretend to do\n",
      "You think you're above the law, don't you?\n",
      "But your hypocrisy is exposed, and I'm here to shout it out loud to you!\n",
      "\n",
      "**The Crowd Goes WILD**\n",
      "\n",
      "Commentator 1: \"This has gotten ridiculous! We need to let them finish!\"\n",
      "\n",
      "Commentator 2: \"I know, I know. This rap battle is getting out of hand.\"\n",
      "\n",
      "Stephen Colbert wraps up his set.\n",
      "\n",
      "**Stephen Colbert**\n",
      "\n",
      "And that's a wrap, folks. John Oliver may have won this battle\n",
      "But I'll be back, and next time, you won't be able to fake the laughter!\n",
      "\n",
      "John Oliver smirks, \"Bring it on, Stephen. I'm ready for number two.\"\n",
      "\n",
      "The crowd cheers as both comedians take a triumphant bow, the commentary team high-fiving each other in excitement.\n",
      "\n",
      "**The End**\n"
     ]
    }
   ],
   "source": [
    "response_message = model.invoke(\n",
    "    \"Simulate a rap battle between Stephen Colbert and John Oliver\"\n",
    ")\n",
    "\n",
    "print(response_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "502e7002-0247-4b2a-84fd-4956f0af1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1121b86e-974d-4e0f-ba8d-917a4cac402b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main themes in these retrieved documents appear to be:\\n\\n1. **Task Decomposition**: Breaking down complex tasks into smaller, manageable subtasks to improve efficiency and effectiveness.\\n2. **Planning and Execution**: The ability of LLMs (Large Language Models) or autonomous agents to plan and execute specific tasks, including self-reflection and refinement.\\n3. **Self-Criticism and Learning**: The use of feedback mechanisms within the planning process to identify areas for improvement and refine future steps.\\n\\nThese themes are related to the topic of \"Task Decomposition with LLM\" (i.e., using LLMs in a task decomposition context).'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | model | StrOutputParser()\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e84ba04-120b-4bb3-8250-8be0427ecd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "430cd591-0664-4f77-9f63-b9c535cb7ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition can be approached using simple prompting (1), task-specific instructions (2), or human inputs. These methods involve different levels of complexity and engagement from both the agent and humans. Task decompositions can also incorporate reflection, learning, and refinement to improve efficiency and quality over time.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAG_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=lambda input: format_docs(input[\"context\"]))\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "# Run\n",
    "chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be74be86-1bde-47fb-930d-52bbcdae1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c91e025c-f0b2-4de1-a667-d9e0de7fb91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition involves breaking down large tasks into smaller subtasks using various methods. There are three primary approaches: \\n\\n1. Using simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", or using task-specific instructions, as shown in Figure 1.\\n2. Employing task-specific instructions, such as writing a story outline for a novel, to guide the agent towards breaking down complex tasks into manageable subtasks.\\n3. Utilizing human inputs, which may involve giving an expert model specific tasks to execute on and logging their results, as depicted in Fig. 1.\\n\\nThese approaches enable agents to efficiently decompose complicated tasks and improve their overall performance by refining subtasks over time.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809fd958-943a-4551-a4bb-c3798212f17f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
